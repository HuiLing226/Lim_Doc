# -*- coding: utf-8 -*-
"""Warblrb10k.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UONWMD-cAG3v2SjDDBxM_jiZZVBWKUNa
"""

import os
import numpy as np
import tensorflow as tf
import librosa
import zipfile
import requests
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.utils import class_weight

# -------------------------------------------------------
# Paths for dataset and metadata
# -------------------------------------------------------
DATASET_ZIP_PATH = "/contents/warblrb.zip"
DATASET_EXTRACT_PATH = "/contents/warblrb"
METADATA_CSV_PATH = "/contents/warblrb_metadata.csv"

# Create parent directories if they do not exist
os.makedirs(os.path.dirname(DATASET_ZIP_PATH), exist_ok=True)
os.makedirs(os.path.dirname(DATASET_EXTRACT_PATH), exist_ok=True)

# -------------------------------------------------------
# URLs for downloading dataset and metadata
# -------------------------------------------------------
DATASET_URL = "https://archive.org/download/warblrb10k_public/warblrb10k_public_wav.zip"
METADATA_URL = "https://ndownloader.figshare.com/files/6035817"

def download_warblrb () :
  if not os.path.exists(DATASET_EXTRACT_PATH):
    # Download zip if it doesn â€™t exist
    if not os.path.exists(DATASET_ZIP_PATH):
      print ("Downloading Warblrb10k dataset ...")
      r = requests.get(DATASET_URL,stream = True)
      with open ( DATASET_ZIP_PATH , "wb") as f:
        for chunk in r. iter_content ( chunk_size =8192) :
          f. write ( chunk )
      print (" Download complete !")

    # Extract the zip
    print ("Extracting dataset ...")
    with zipfile.ZipFile (DATASET_ZIP_PATH , "r") as zip_ref :
      zip_ref . extractall ( DATASET_EXTRACT_PATH )
    print ("Extraction complete !")
  else :
    print ("Dataset already exists, skipping download.")

  return DATASET_EXTRACT_PATH

def download_metadata():
    # Use the path from configuration
    local_csv = METADATA_CSV_PATH
    if not os.path.exists(local_csv):
        print("Downloading metadata CSV ...")
        # Removed trailing spaces from the URL
        response = requests.get(METADATA_URL)
        with open(local_csv, 'wb') as f:
            f.write(response.content)

    df = pd.read_csv(local_csv)
    print(f"Loaded metadata with {len(df)} entries")

    # Create a dictionary mapping itemid (as string) to hasbird label
    label_dict = {str(row['itemid']): int(row['hasbird'])
                  for _, row in df.iterrows()}

    print(f"Labels assigned: {sum(label_dict.values())} bird, "
          f"{len(label_dict) - sum(label_dict.values())} non-bird")

    return label_dict

def find_loudest_segment(audio, sr, duration=3.0, step=0.1):
    samples_per_segment = int(sr * duration)
    step_samples = int(sr * step)
    max_energy = -np.inf
    best_segment = None

    # Check if audio is long enough for at least one segment
    if len(audio) < samples_per_segment:
        # Pad if too short
        return np.pad(audio, (0, samples_per_segment - len(audio)), mode='constant')

    # Slide window across the audio
    for start in range(0, len(audio) - samples_per_segment + 1, step_samples):
        segment = audio[start:start + samples_per_segment]
        # Calculate Root Mean Square (RMS) energy
        energy = np.sqrt(np.mean(segment ** 2))
        if energy > max_energy:
            max_energy = energy
            best_segment = segment

    # In case no segment was chosen (edge case: very short audio relative to step)
    if best_segment is None:
        best_segment = audio[:samples_per_segment]

    # Ensure correct length (pad if needed)
    best_segment = np.pad(best_segment, (0, max(0, samples_per_segment - len(best_segment))))

    return best_segment

# Audio processing parameters
SAMPLE_RATE = 16000
TARGET_CLIP_DURATION = 3.0
SAMPLES_PER_CLIP = int(SAMPLE_RATE * TARGET_CLIP_DURATION)
WINDOW_STEP = 0.1  # 100 ms step for find_loudest_segment
N_MELS = 16
FFT_SIZE = 512
HOP_LENGTH = 256

def process_audio_file(filepath, label):
    """Loads an audio file, extracts a segment based on label, and computes its Mel spectrogram."""
    try:
        # 1. Load audio
        audio, sr = librosa.load(filepath, sr=SAMPLE_RATE)

        # 2. Extract segment
        # For bird calls, find the loudest segment (informative portion).
        # since bird sounds may not span the entire clip .
        if label == 1:
            # For bird calls , find the loudest segment
            segment = find_loudest_segment(audio, sr, TARGET_CLIP_DURATION, WINDOW_STEP)
        else:
            # For non-bird, take a random segment to introduce variability
            if len(audio) >= SAMPLES_PER_CLIP:
                start = np.random.randint(0, len(audio) - SAMPLES_PER_CLIP + 1)
                segment = audio[start:start + SAMPLES_PER_CLIP]
            else:
                # If audio is shorter than desired clip, pad it
                segment = np.pad(audio, (0, SAMPLES_PER_CLIP - len(audio)), mode='constant')

        # 3. Extract Mel Spectrogram
        mel_spec = librosa.feature.melspectrogram(
            y=segment,
            sr=SAMPLE_RATE,
            n_fft=FFT_SIZE,
            hop_length=HOP_LENGTH,
            n_mels=N_MELS
        )
        mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)

        return mel_spec_db, label

    except Exception as e:
        print(f"Error processing {filepath}: {e}")
        return None, None

# Download and extract dataset
DATA_DIR = download_warblrb()

# Load metadata using download_metadata function
LABEL_DICT = download_metadata()

print("Finding audio files ...")
all_wav_files = []
for root, _, files in os.walk(DATA_DIR):
    for file in files:
        if file.endswith(".wav"):
            all_wav_files.append(os.path.join(root, file))

print(f"Found {len(all_wav_files)} .wav files. Processing all files ...")

# Lists to hold features and labels
X_features = []
y_labels = []
processed_count = 0

for filepath in all_wav_files:
    filename = os.path.basename(filepath)
    file_id = os.path.splitext(filename)[0]  # e.g., "99687"

    # Skip if file_id not in metadata
    if file_id not in LABEL_DICT:
        continue

    label = LABEL_DICT[file_id]
    features, label = process_audio_file(filepath, label)

    if features is not None and label is not None:
        X_features.append(features)
        y_labels.append(label)
        processed_count += 1

        if processed_count % 500 == 0:
            print(f"Processed {processed_count} files ...")

print(f"Final dataset size: {len(X_features)} samples")

# Convert to NumPy arrays and add channel dimension for CNN
X = np.array(X_features)[..., np.newaxis]  # Shape: (N, Time, Freq, 1)
y = np.array(y_labels)

from sklearn.model_selection import train_test_split
from sklearn.utils import class_weight
import numpy as np

USE_CLASS_WEIGHTS = True  # Set to False to disable class weights

print("Splitting data ...")
X_train, X_val, y_train, y_val = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

class_weights = None  # Default to None
if USE_CLASS_WEIGHTS:
    print("Computing class weights for imbalanced dataset ...")
    try:
        class_weights = class_weight.compute_class_weight(
            class_weight='balanced',
            classes=np.unique(y_train),
            y=y_train
        )
        class_weights = dict(enumerate(class_weights))
        print(f"Class weights enabled: {class_weights}")
    except ValueError as e:
        print(f"Warning: Could not compute class weights: {e}. Training without class weights.")
        class_weights = None
        USE_CLASS_WEIGHTS = False  # Disable flag if computation fails
else:
    print("Class weights disabled.")

print("Defining model ...")
model = tf.keras.Sequential([
    tf.keras.layers.Conv2D(8, (3, 3), activation='relu', input_shape=X_train.shape[1:]),
    tf.keras.layers.MaxPooling2D((2, 2)),
    tf.keras.layers.Conv2D(16, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D((2, 2)),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(16, activation='relu'),
    tf.keras.layers.Dense(2, activation='softmax')  # 2 classes: bird / no-bird
])

model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

model.summary()

# Training configuration
EPOCHS = 10
BATCH_SIZE = 32

training_msg = f"Training model for {EPOCHS} epochs"
if USE_CLASS_WEIGHTS and class_weights:
    training_msg += " with class weights ..."
else:
    training_msg += " without class weights ..."
print(training_msg)

# Train the model
history = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    class_weight=class_weights if USE_CLASS_WEIGHTS and class_weights else None
)

print("Converting model to TensorFlow Lite ...")
converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]  # Quantization
tflite_model = converter.convert()

suffix = "_with_weights" if USE_CLASS_WEIGHTS else "_no_weights"
tflite_filename = f"bird_activity_simplified{suffix}.tflite"

with open(tflite_filename, "wb") as f:
    f.write(tflite_model)

print(f"TFLite model saved as '{tflite_filename}'")

# Final validation accuracy
val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)
print(f"Final Validation Accuracy: {val_accuracy:.4f}")