# -*- coding: utf-8 -*-
"""TC_quant.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15bcBr3UZALnmhpAiuNurZSXmQ5r_wk61
"""

import os
import numpy as np
import tensorflow as tf
import librosa
import kagglehub
from sklearn.utils import class_weight

# -------------------------------------------------------
# Download TinyChirp Dataset
# -------------------------------------------------------
print("Downloading TinyChirp dataset ...")
path = kagglehub.dataset_download("zhaolanhuang/tinychirp")
print("Path to dataset files:", path)

# -------------------------------------------------------
# Parameters
# -------------------------------------------------------
SAMPLE_RATE = 16000
TARGET_CLIP_DURATION = 3.0
SAMPLES_PER_CLIP = int(SAMPLE_RATE * TARGET_CLIP_DURATION)
WINDOW_STEP = 0.1
N_MELS = 16
FFT_SIZE = 512
HOP_LENGTH = 256
USE_CLASS_WEIGHTS = True

# -------------------------------------------------------
# Segment Extraction
# -------------------------------------------------------
def find_loudest_segment(audio, sr, duration=3.0, step=0.1):
    samples_per_segment = int(sr * duration)
    step_samples = int(sr * step)
    max_energy = -np.inf
    best_segment = None

    # Check if audio is long enough for at least one segment
    if len(audio) < samples_per_segment:
        # Pad if too short
        return np.pad(audio, (0, samples_per_segment - len(audio)), mode='constant')

    # Slide window across the audio
    for start in range(0, len(audio) - samples_per_segment + 1, step_samples):
        segment = audio[start:start + samples_per_segment]
        # Calculate Root Mean Square (RMS) energy
        energy = np.sqrt(np.mean(segment ** 2))
        if energy > max_energy:
            max_energy = energy
            best_segment = segment

    # In case no segment was chosen (edge case: very short audio relative to step)
    if best_segment is None:
        best_segment = audio[:samples_per_segment]

    # Ensure correct length (pad if needed)
    best_segment = np.pad(best_segment, (0, max(0, samples_per_segment - len(best_segment))))

    return best_segment

# -------------------------------------------------------
# Audio Processing
# -------------------------------------------------------
def process_audio_file(filepath, label):
    """Loads an audio file, extracts a segment based on label, and computes its Mel spectrogram."""
    try:
        # 1. Load audio
        audio, sr = librosa.load(filepath, sr=SAMPLE_RATE)

        # 2. Extract segment
        # For bird calls, find the loudest segment (informative portion).
        # since bird sounds may not span the entire clip .
        if label == 1:
            # For bird calls , find the loudest segment
            segment = find_loudest_segment(audio, sr, TARGET_CLIP_DURATION, WINDOW_STEP)
        else:
            # For non-bird, take a random segment to introduce variability
            if len(audio) >= SAMPLES_PER_CLIP:
                start = np.random.randint(0, len(audio) - SAMPLES_PER_CLIP + 1)
                segment = audio[start:start + SAMPLES_PER_CLIP]
            else:
                # If audio is shorter than desired clip, pad it
                segment = np.pad(audio, (0, SAMPLES_PER_CLIP - len(audio)), mode='constant')

        # 3. Extract Mel Spectrogram
        mel_spec = librosa.feature.melspectrogram(
            y=segment,
            sr=SAMPLE_RATE,
            n_fft=FFT_SIZE,
            hop_length=HOP_LENGTH,
            n_mels=N_MELS
        )
        mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)
        # Normalize [0,1]
        mel_norm = (mel_spec_db - mel_spec_db.min()) / (mel_spec_db.max() - mel_spec_db.min() + 1e-8)

        return mel_norm.astype(np.float32), label

    except Exception as e:
        print(f"Error processing {filepath}: {e}")
        return None, None

# -------------------------------------------------------
# Load Dataset Splits
# -------------------------------------------------------
def load_tinychirp_split(split_dir):
    X, y = [], []
    for root, _, files in os.walk(split_dir):
        for file in files:
            if file.endswith((".wav", ".flac", ".mp3", ".ogg")):
                filepath = os.path.join(root, file)

                # TinyChirp uses "target" (bird) and "non_target" (no bird)
                if "non_target" in root.lower():
                    label = 0   # no bird
                elif "target" in root.lower():
                    label = 1   # bird
                else:
                    # Fallback: try to infer from directory structure
                    print(f"Warning: Cannot determine label for {filepath}, skipping")
                    continue

                features, lbl = process_audio_file(filepath, label)
                if features is not None:
                    X.append(features)
                    y.append(lbl)
    return np.array(X)[..., np.newaxis], np.array(y, dtype=np.int32)

print("Loading dataset splits ...")
X_train, y_train = load_tinychirp_split(os.path.join(path, "training"))
X_val, y_val     = load_tinychirp_split(os.path.join(path, "validation"))
X_test, y_test   = load_tinychirp_split(os.path.join(path, "testing"))

print("Shapes:")
print(" Train:", X_train.shape, y_train.shape)
print(" Val:",   X_val.shape, y_val.shape)
print(" Test:",  X_test.shape, y_test.shape)

print("Class distribution (train):", np.bincount(y_train))
print("Class distribution (val):", np.bincount(y_val))
print("Class distribution (test):", np.bincount(y_test))

# -------------------------------------------------------
# Compute Class Weights (for imbalance handling)
# -------------------------------------------------------
print("Computing class weights ...")

# Ensure integer labels
y_train = np.asarray(y_train, dtype=np.int64)
classes = np.unique(y_train)
class_weights_array = class_weight.compute_class_weight(
    class_weight='balanced', classes=classes, y=y_train
)
class_weights = dict(zip(classes, class_weights_array))
print("Class weights:", class_weights)

# -------------------------------------------------------
# Define CNN Model
# -------------------------------------------------------
print("Defining model ...")
model = tf.keras.Sequential([
    tf.keras.layers.Conv2D(8, (3, 3), activation='relu', input_shape=X_train.shape[1:]),
    tf.keras.layers.MaxPooling2D((2, 2)),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Conv2D(16, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D((2, 2)),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dropout(0.4),
    tf.keras.layers.Dense(2, activation='softmax')
])

model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)
model.summary()

# -------------------------------------------------------
# Train Model
# -------------------------------------------------------
EPOCHS = 10
BATCH_SIZE = 32
print(f"Training model for {EPOCHS} epochs ...")
history = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    class_weight=class_weights if USE_CLASS_WEIGHTS else None
)

# -------------------------------------------------------
# Quantization to INT8
# -------------------------------------------------------
def representative_dataset():
    for i in range(min(100, len(X_train))):
        data = X_train[i].astype(np.float32)
        data = np.expand_dims(data, axis=0)
        yield [data]

print("Converting model to TensorFlow Lite (Full INT8 Quantization)...")
converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = representative_dataset
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_input_type = tf.int8
converter.inference_output_type = tf.int8
tflite_model = converter.convert()

tflite_filename = "bird_activity_detector_int8.tflite"
with open(tflite_filename, "wb") as f:
    f.write(tflite_model)

print(f"TFLite model saved as '{tflite_filename}'")

# -------------------------------------------------------
# Evaluate
# -------------------------------------------------------
val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)
test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)
print(f"Final Validation Accuracy: {val_accuracy:.4f}")
print(f"Final Test Accuracy: {test_accuracy:.4f}")

from google.colab import files

# Download quantized model
files.download(tflite_filename)

interpreter = tf.lite.Interpreter(model_path=tflite_filename)
interpreter.allocate_tensors()

print("Input:", interpreter.get_input_details())
print("Output:", interpreter.get_output_details())
