# -*- coding: utf-8 -*-
"""species_modified.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AZaP3zSLvTVvAJI4v0gIWCN048MmHnGs
"""

!pip install librosa tensorflow scikit-learn tqdm matplotlib

import os
import librosa
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from tqdm import tqdm
import matplotlib

# =============================
# Set Dataset Path
# =============================
DATASET_PATH = r"C:\Users\End User\Downloads\seabird3s-20250918T013234Z-1-001\seabird3s"

# =============================
# Check dataset
# =============================
if os.path.exists(DATASET_PATH):
    print(f"Dataset path found: {DATASET_PATH}")
    class_names = [d for d in os.listdir(DATASET_PATH)
                   if os.path.isdir(os.path.join(DATASET_PATH, d)) and not d.startswith(".")]
    print(f"Found {len(class_names)} classes: {class_names}")

    # Count files in each class
    for class_name in class_names:
        class_path = os.path.join(DATASET_PATH, class_name)
        wav_files = [f for f in os.listdir(class_path) if f.endswith(".wav")]
        print(f"{class_name}: {len(wav_files)} WAV files")
else:
    print(f"Error: Dataset path not found: {DATASET_PATH}")
    print(f"Please check the path and try again.")

# =============================
# Audio to Mel Spectrogram
# =============================
def audio_to_mel(
    path,
    sr=44100,
    n_mels=224,
    duration=3.0,
    img_size=(224, 224)
):

    # Load 3- second audio clip
    y, sr = librosa.load(path, sr=sr, duration=duration)

    # Create mel - spectrogram
    S = librosa.feature.melspectrogram(
        y=y, sr=sr, n_mels=n_mels, n_fft=2048, hop_length=512)

    # Convert to decibels
    S_dB = librosa.power_to_db(S, ref=np.max)

    # Normalize to 0 -1 range
    S_norm = (S_dB - S_dB.min()) / (S_dB.max() - S_dB.min() + 1e-8)

    # Convert to RGB image using viridis colormap
    S_rgb = plt.get_cmap("viridis")(S_norm)[..., :3]

    # Resize to 224 x224
    S_rgb_resized = tf.image.resize(S_rgb, img_size).numpy()

    return S_rgb_resized.astype(np.float32)

# =============================
# Build dataset paths and labels
# =============================
file_paths = []
labels = []
class_names = sorted([d for d in os.listdir(DATASET_PATH)
                      if os.path.isdir(os.path.join(DATASET_PATH, d)) and not d.startswith(".")])
for idx, class_name in enumerate(class_names):
    class_folder = os.path.join(DATASET_PATH, class_name)
    wav_files = [f for f in os.listdir(class_folder) if f.endswith(".wav")]
    for f in wav_files:
        file_paths.append(os.path.join(class_folder, f))
        labels.append(idx)

# -------------------------------
# Prepare tf.data.Dataset for memory-efficient training
# -------------------------------
from keras.applications.mobilenet_v3 import preprocess_input

# Function to preprocess a single file
def preprocess_file(file_path, label):
    # Convert the TensorFlow tensor to a Python string
    file_path_str = file_path.numpy().decode('utf-8')
    mel = audio_to_mel(file_path_str)
    mel = preprocess_input((mel * 255).astype(np.float32))
    return mel, label

# Split into train (80%), val (10%), test (10%)
train_paths, temp_paths, train_labels, temp_labels = train_test_split(
    file_paths, labels, test_size=0.2, stratify=labels, random_state=42
)
val_paths, test_paths, val_labels, test_labels = train_test_split(
    temp_paths, temp_labels, test_size=0.5, stratify=temp_labels, random_state=42
)

# Function to create tf.data.Dataset
def create_dataset(paths, labels, batch_size=32, shuffle=True):
    dataset = tf.data.Dataset.from_tensor_slices((paths, labels))
    dataset = dataset.map(lambda x, y: tf.py_function(preprocess_file, [x, y], [tf.float32, tf.int32]),
                          num_parallel_calls=tf.data.AUTOTUNE)
    # Set the shape explicitly after the py_function call
    dataset = dataset.map(lambda x, y: (tf.ensure_shape(x, (224, 224, 3)), tf.ensure_shape(y, ())))
    if shuffle:
        dataset = dataset.shuffle(1000)
    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)
    return dataset

# Create datasets
train_dataset = create_dataset(train_paths, train_labels)
val_dataset = create_dataset(val_paths, val_labels, shuffle=False)
test_dataset = create_dataset(test_paths, test_labels, shuffle=False)

# -------------------------------
# Build MobileNetV3-based model
# -------------------------------
from keras.applications import MobileNetV3Small

# Load pre-trained base model without top classification layer
base_model = MobileNetV3Small(input_shape=(224, 224, 3), include_top=False, weights="imagenet")
base_model.trainable = False  # Freeze base model

# Add classification layers
model = keras.Sequential([
    base_model,
    keras.layers.GlobalAveragePooling2D(),
    keras.layers.Dropout(0.2),
    keras.layers.Dense(len(class_names), activation="softmax")
])

# Compile model
model.compile(
    optimizer=keras.optimizers.Adam(learning_rate=0.001),
    loss="sparse_categorical_crossentropy",
    metrics=["accuracy"]
)
print("Model built successfully!")
model.summary()

# =============================
# Train model
# =============================
# Train for 20 epochs
print("Training model...")
history = model.fit(
    train_dataset,
    validation_data=val_dataset,
    epochs=20,
    batch_size=32,
    verbose=1)

# =============================
# Evaluation
# =============================
from sklearn . metrics import classification_report
print("Evaluating model on test set...")

# Get test accuracy
test_loss, test_accuracy = model.evaluate(test_dataset, verbose=0)
print(f"Test Accuracy: {test_accuracy:.1%}")

y_true, y_pred, y_probs = [], [], []
for batch_x, batch_y in test_dataset:
    preds = model.predict(batch_x, verbose=0)
    y_true.extend(batch_y.numpy())
    y_pred.extend(np.argmax(preds, axis=1))
    y_probs.extend(preds) # store probabilities for confidence

# Generate comprehensive classification report
print("\n=== CLASSIFICATION REPORT ===")
print(classification_report(y_true, y_pred, target_names=class_names, digits=3))

# Display dataset statistics for context
print("\nDataset Statistics:")
print(f"- Total samples: {len(file_paths)}")
print(f"- Number of classes: {len(class_names)}")
print(f"- Test set size: {len(test_paths)} samples ({len(test_paths)/len(file_paths)*100:.1f}% of total)")

# =============================
# Create confusion matrix
# =============================
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
cm = confusion_matrix(y_true, y_pred)

# Plot confusion matrix
plt.figure(figsize=(10, 8))
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)
disp.plot(cmap="Blues", xticks_rotation=45)
plt.title(f"Confusion Matrix - Test Accuracy: {test_accuracy:.1%}")
plt.tight_layout()
plt.show()

print("\n=== SAMPLE PREDICTIONS ===")
for i in range(min(5, len(test_paths))):  # Show up to 5 examples
    true_class = class_names[y_true[i]]
    pred_class = class_names[y_pred[i]]
    confidence = np.max(y_probs[i])

    status = "Correct" if y_true[i] == y_pred[i] else "Wrong"
    print(f"{status} - True: {true_class}, Predicted: {pred_class} (confidence: {confidence:.2f})")

def plot_training_history(history):
    plt.figure(figsize=(12, 4))

    # Accuracy
    plt.subplot(1, 2, 1)
    plt.plot(history.history['accuracy'], label='Train (Phase 1)')
    plt.plot(history.history['val_accuracy'], label='Validation (Phase 1)')
    plt.title("Model Accuracy")
    plt.xlabel("Epoch")
    plt.ylabel("Accuracy")
    plt.legend()
    plt.grid(True)

    # Loss
    plt.subplot(1, 2, 2)
    plt.plot(history.history['loss'], label='Train (Phase 1)')
    plt.plot(history.history['val_loss'], label='Validation (Phase 1)')
    plt.title("Model Loss")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.legend()
    plt.grid(True)

    plt.tight_layout()
    plt.show()

# Call after training
plot_training_history(history)